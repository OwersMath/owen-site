<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Owen&#39;s Math Portal</title>
    <link>https://drummond.nyc/</link>
    <description>Recent content on Owen&#39;s Math Portal</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 26 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://drummond.nyc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Collection of Exercises from Real Analysis II</title>
      <link>https://drummond.nyc/post/real-analysis-ex/</link>
      <pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/real-analysis-ex/</guid>
      <description>&lt;p&gt;The following exercises are an assortment of homework problems from &lt;em&gt;MATH 502 - Theory&#xA;of Functions of a Real Variable II&lt;/em&gt; with Professor Dennis Kriventsov at Rutgers University.&#xA;Topics include Radon Measures, weak convergence, Haar measures, Fourier analysis, PDEs,&#xA;distributions, and probability theory.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Most Beautiful Result in Calculus</title>
      <link>https://drummond.nyc/post/cosint/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/cosint/</guid>
      <description>&lt;p&gt;Today, we will evaluate the integral&#xA;$$&#xA;\int_{-\infty}^{\infty} \frac{\cos(x)}{x^2+1} dx&#xA;$$&#xA;using Cauchy&amp;rsquo;s Residue Theorem and contour integration. This is one of the most beautiful results in all of calculus, and the solution is rather elegant. To begin, let us define the following function in&#xA;&#xD;&#xA;\(\mathbb{C}\)&#xD;&#xA;:&#xA;$$&#xA;f(z)=\frac{e^{iz}}{z^2+1}&#xA;$$&#xA;and let us use the canonical contour, that is, the top half of a semicircle in the complex plane. Let us define this contour as&#xA;&#xD;&#xA;\(C\)&#xD;&#xA;&#xA;, with radius&#xA;&#xD;&#xA;\(R\)&#xD;&#xA;. Note that&#xA;&#xD;&#xA;\(f(z)\)&#xD;&#xA;&#xA;had two singularities, one at&#xA;&#xD;&#xA;\(z=-i\)&#xD;&#xA;&#xA;and the other at&#xA;&#xD;&#xA;\(z=i\)&#xD;&#xA;.&#xA;Only&#xA;&#xD;&#xA;\(z=i\)&#xD;&#xA;&#xA;is inside of our contour&#xA;&#xD;&#xA;\(C\)&#xD;&#xA;, as seen below:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dirichlet Integral - Two Ways</title>
      <link>https://drummond.nyc/post/dirichlet/</link>
      <pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/dirichlet/</guid>
      <description>&lt;p&gt;Here we will solve the Dirichlet Integral using two different techniques. The Dirichlet Integral is defined as&#xA;$$&#xA;\int_{0}^{\infty} \frac{\sin(x)}{x} dx&#xA;$$&lt;/p&gt;&#xA;&lt;h3 id=&#34;feynman-integration&#34;&gt;Feynman Integration&lt;/h3&gt;&#xA;&lt;p&gt;We employ Feynman&amp;rsquo;s Integration trick here by first defining the function&#xA;$$&#xA;I(\alpha)=\int_{0}^{\infty} \frac{\sin(x)}{x} e^{-\alpha x} dx&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;and notice that because&#xA;&#xD;&#xA;\(|\frac{\sin(x)}{x}| \leq 1 \)&#xD;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\lim_{\alpha \rightarrow \infty} |\int_{0}^{\infty} \frac{\sin(x)}{x} e^{-\alpha x} dx| \leq \int_{0}^{\infty} e^{-\alpha x} dx = \frac{1}{\alpha}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;so&#xA;&#xD;&#xA;\(I(\alpha) \)&#xD;&#xA;&#xA;vanishes as&#xA;&#xD;&#xA;\(\alpha \rightarrow \infty \)&#xD;&#xA;&#xA;and thus we can continue with Fenyman&amp;rsquo;s technique:&#xA;$$&#xA;\frac{\partial I(\alpha)}{\partial \alpha} = \frac{\partial}{\partial \alpha} \int_{0}^{\infty} \frac{\sin(x)}{x} e^{-\alpha x} dx = -\int_{0}^{\infty} x \frac{\sin(x)}{x} e^{-\alpha x} dx = -\int_{0}^{\infty} \sin(x) e^{-\alpha x} dx&#xA;$$&#xA;now by integration by parts, we have that&#xA;$$&#xA;-\int_{0}^{\infty} \sin(x) e^{-\alpha x} dx = -1+\alpha \int_{0}^{\infty} \cos(x) e^{-\alpha x} dx&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integral of the Day - 7/2/2023</title>
      <link>https://drummond.nyc/post/7-2-int/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/7-2-int/</guid>
      <description>&lt;p&gt;Today, we will be evaluating the integral&#xA;$$&#xA;\int_{-\infty}^{\infty} e^{ax^2+bx+c} dx \hspace{1cm} a \in \mathbb{R^{-}}, b \in \mathbb{R}, c \in \mathbb{R}&#xA;$$&#xA;The restriction of&#xA;&#xD;&#xA;\(a\)&#xD;&#xA;&#xA;to&#xA;&#xD;&#xA;\(\mathbb{R^{-}}\)&#xD;&#xA;&#xA;is required for the convergence of this integral. My thought process for this integral was initially to minipulate the integrand in such a way that we can employ the result of the Gaussian integral, namely,&#xA;&#xD;&#xA;\(\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi}\)&#xD;&#xA;&#xA;. To do this, we complete the square on&#xA;&#xD;&#xA;\(f(x)=ax^2+bx+c\)&#xD;&#xA;&#xA;:&#xA;$$&#xA;y=ax^2+bx+c \implies y-c=ax^2+bx=a(x^2+\frac{b}{a}x) \implies \frac{y-c}{a}=x^2+\frac{b}{a}x&#xA;$$&#xA;Further,&#xA;$$&#xA;\frac{y-c}{a}+\frac{b^2}{4a^2}=x^2+\frac{b}{a}x+\frac{b^2}{4a^2} \implies \frac{y-c}{a}=(x+\frac{b}{2a})^2-\frac{b^2}{4a^2}&#xA;$$&#xA;Lastly,&#xA;$$&#xA;y=a(x+\frac{b}{2a})^2-\frac{b^2}{4a}+c&#xA;$$&#xA;Thus we have that&#xA;$$&#xA;I=\int_{-\infty}^{\infty} e^{ax^2+bx+c} dx=\int_{-\infty}^{\infty} e^{a(x+\frac{b}{2a})^2-\frac{b^2}{4a}+c} dx=e^{-\frac{b^2}{4a}+c} \int_{-\infty}^{\infty} e^{a(x+\frac{b}{2a})^2} dx&#xA;$$&#xA;Given that this integrand spans all of&#xA;&#xD;&#xA;\(\mathbb{R}\)&#xD;&#xA;&#xA;we can employ the substitution&#xA;&#xD;&#xA;\(t=x+\frac{b}{2a}\)&#xD;&#xA;&#xA;and our bounds will remain the same. Thus,&#xA;$$&#xA;I=e^{-\frac{b^2}{4a}+c} \int_{-\infty}^{\infty} e^{at^2} dt&#xA;$$&#xA;and since&#xA;&#xD;&#xA;\(a\)&#xD;&#xA;&#xA;is negative, we can write&#xA;$$&#xA;I=e^{-\frac{b^2}{4a}+c} \int_{-\infty}^{\infty} e^{-(\sqrt{-a}t)^2} dt&#xA;$$&#xA;Now letting&#xA;&#xD;&#xA;\(v=\sqrt{-a}t\)&#xD;&#xA;&#xA;we have that&#xA;&#xD;&#xA;\(dv=\sqrt{-a} dt \implies \frac{dv}{\sqrt{-a}}=dt\)&#xD;&#xA;&#xA;and thus&#xA;$$&#xA;I=e^{-\frac{b^2}{4a}+c} \int_{-\infty}^{\infty} e^{-(v)^2} \frac{dv}{\sqrt{-a}} \implies I=\frac{e^{-\frac{b^2}{4a}+c}}{\sqrt{-a}} \sqrt{\pi} = e^{-\frac{b^2}{4a}+c} \sqrt{-\frac{\pi}{a}}&#xA;$$&#xA;and we&amp;rsquo;re done.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Space of Invertible Matricies is Dense in the Space of All Matricies</title>
      <link>https://drummond.nyc/post/invrt-proof/</link>
      <pubDate>Sat, 27 May 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/invrt-proof/</guid>
      <description>&lt;p&gt;To prove that the space of all invetible matricies is dense in the space of all matricies, it will suffice to show that the space of all invertible matricies is dense the space of matricies with distinct eigenvalues, as the space of matricies with distinct eigenvalues is dense in the space of all matricies. Denote&#xA; \(E(n, \mathbb{R}) \) &#xA;as the space of matricies with n distinct eigenvalues. Formally,&#xA;$$&#xA;E(n, ℝ) = { \begin{bmatrix}&#xA;a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\&#xA;a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\&#xA;\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots    \\&#xA;a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \\&#xA;\end{bmatrix} : a_{ij} \in ℝ, \hspace{0.25cm} \textnormal{and} \hspace{0.25cm} \lambda_{1}, \lambda_{2}, &amp;hellip; \lambda_{n} \hspace{0.25cm} \textnormal{all distinct eigenvalues} }&#xA;$$&#xA;Now, by Schuer&amp;rsquo;s Theorem, we have that  \(\exists \)  a unitary matrix U and upper triangular matrix D such that for any  \(E_0 \in E(n,\mathbb{R}) \)  we have that  \(E_0 = UDU^{-1}  \) , where&#xA;$$&#xA;D = \begin{bmatrix}&#xA;\alpha_{1} &amp;amp; c_{12} &amp;amp; \cdots &amp;amp; c_{1n} \\&#xA;0 &amp;amp; \alpha_{2} &amp;amp; &amp;hellip; &amp;amp; c_{2n} \\&#xA;\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots    \\&#xA;0 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; \alpha_{n} \\ \end{bmatrix}&#xA;$$&#xA;and  \(\alpha_{1}, ..., \alpha_{n} \)  are the distinct eigenvalues of  \(E_{0} \)  and  \(c_{ij} \in \mathbb{R} \) . Now for each n,  \(\exists \epsilon_{1}^m, \epsilon_{2}^m, ..., \epsilon_{n}^m \)  such that  \(\epsilon_{i}^{m} \rightarrow 0 \)  as  \(m \rightarrow \infty \)  and  \(\alpha_{i}^{m} = \alpha_{i} + \epsilon_{i}^{m} \neq 0 \)  for  \(1 \leq i \leq n \)  and all  \(\alpha_{i}^{m} \)  are distinct. Set&#xA;$$&#xA;D^m = \begin{bmatrix}&#xA;\alpha_{1}^{m} &amp;amp; \tilde{c_{12}} &amp;amp; \cdots &amp;amp; \tilde{c_{1n}} \\&#xA;0 &amp;amp; \alpha_{2}^{m} &amp;amp; &amp;hellip; &amp;amp; \tilde{c_{2n}} \\&#xA;\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots    \\&#xA;0 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; \alpha_{n}^{m} \\ \end{bmatrix}&#xA;$$&#xA;and  \(A^m=UD^{m}U^{*} \) . Because  \(A^m \)  is constructed in such a way that  \(\alpha_{1}^{m}, ..., \alpha_{n}^{m} \)  are the eigenvalues of  \(A^m \) ,  \(A^m \)  has n distinct non-zero eigenvalues, and thus  \(A^m \)  is invertible. Finally,&#xA;$$&#xA;A-A^m=UDU^{\ast}-UD^{m}U^{\ast}=U(D-D^{m})U^{\ast} \implies ||A-A^m|| \leq ||U|| \hspace{0.12cm} ||D-D^m|| \hspace{0.12cm} ||U^{\ast}|| = ||D-D^{m}|| \rightarrow 0 \hspace{0.25cm} \textnormal{as} \hspace{0.25cm} m \rightarrow \infty&#xA;$$&#xA;Thus, the spaces of all  \(n \times n \)  invertible matricies is dense in  \(E(n, \mathbb{R}) \) , which suffices to show that the space of all  \(n \times n \)  matricies is dense in   \(M(n, \mathbb{R}) \) , the space of all  \(n \times n \)  matricies since  \(E(n, \mathbb{R}) \)  is dense in  \(M(n, \mathbb{R}) \) .&lt;/p&gt;</description>
    </item>
    <item>
      <title>First Fundamental Form</title>
      <link>https://drummond.nyc/post/first-fundamental-form/</link>
      <pubDate>Thu, 04 May 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/first-fundamental-form/</guid>
      <description>&lt;p&gt;In this article, we will examine the nature and utility of the first fundamental form, a quadratic form on a surface. Given a curve parametrized by&#xA;&#xD;&#xA;\(u=u(t)\)&#xD;&#xA;&#xA;and&#xA;&#xD;&#xA;\(v=v(t)\)&#xD;&#xA;&#xA;which lies on a surface&#xA;&#xD;&#xA;\(X\)&#xD;&#xA;&#xA;parametrized by&#xA;&#xD;&#xA;\(X=X(u,v)\)&#xD;&#xA;&#xA;we have that&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;ds = |\frac{dX}{dt}| dt = |X_u \frac{du}{dt} + X_v \frac{dv}{dt}| dt = \sqrt{(X_u \dot{u} + X_v \dot{v}) \cdot (X_u \dot{u} + X_v \dot{v})}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;Now defining the coefficients, called the First Fundamental Form coefficients E, F and G, we have&lt;/p&gt;</description>
    </item>
    <item>
      <title>Evaluating the Gaussian Integral</title>
      <link>https://drummond.nyc/post/evaluating-the-gaussian-integral/</link>
      <pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/evaluating-the-gaussian-integral/</guid>
      <description>&lt;p&gt;The Gaussian Integral is given by&#xA;$$&#xA;\int_{-\infty}^{\infty} e^{-x^2} dx&#xA;$$&#xA;This is a beautiful integral with many important applications to probability and statistics, namely normal distributions. Here, we will evaluate this integral using techniques from Calculus 3. First, if we define&#xA;&#xD;&#xA;\(I=\int_{-\infty}^{\infty} e^{-x^2} dx\)&#xD;&#xA;&#xA;we have that&#xA;$$&#xA;I^2=\int_{-\infty}^{\infty} e^{-x^2} dx \int_{-\infty}^{\infty} e^{-y^2} dy= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-x^2-y^2} dy dx= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-(x^2+y^2)} dy dx&#xA;$$&#xA;From here, we will preform a change into polar coordinates, with&#xA;&#xD;&#xA;\((x,y) \rightarrow (t, \theta)\)&#xD;&#xA;&#xA;and&#xA;&#xD;&#xA;\(x=r\cos\theta\)&#xD;&#xA;&#xA;,&#xA;&#xD;&#xA;\(y=r\sin\theta\)&#xD;&#xA;&#xA;. From this, since&#xA;&#xD;&#xA;\(r^2=x^2+y^2\)&#xD;&#xA;&#xA;,&#xA;&#xD;&#xA;\(r \in (0,\infty)\)&#xD;&#xA;&#xA;and&#xA;&#xD;&#xA;\(\theta \in (0, 2\pi)\)&#xD;&#xA;&#xA;we have that our integral is now&#xA;$$&#xA;I^2=\int_{0}^{\infty} \int_{0}^{2\pi} re^{-r^2} d\theta dr&#xA;$$&#xA;after this change of coordinates. By Fubini&amp;rsquo;s theorem, we have that&#xA;$$&#xA;I^2=\int_{0}^{\infty} \int_{0}^{2\pi} re^{-r^2} d\theta dr = \int_{0}^{2\pi} d\theta \int_{0}^{\infty} re^{-r^2} dr = 2\pi \int_{0}^{\infty} re^{-r^2} dr&#xA;$$&#xA;Now evaulating this integral of one dimension with the substitution&#xA;$$&#xA;t=r^2 \implies \sqrt{t}=r \implies dt=2rdr \implies rdr=\frac{dt}{2}&#xA;$$&#xA;we have that&lt;/p&gt;</description>
    </item>
    <item>
      <title>Orthonormal Vectors are Linearly Independent</title>
      <link>https://drummond.nyc/post/orthonormal-vectors-are-linearly-independent/</link>
      <pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/orthonormal-vectors-are-linearly-independent/</guid>
      <description>&lt;p&gt;For a set of orthonormal vectors&#xA;&#xD;&#xA;\((v_1,v_2,...,v_m)\)&#xD;&#xA;&#xA;in an m-dimensional vector space&#xA;, and set of constants&#xA;&#xD;&#xA;\(r_1,r_2,...r_m \in \mathbb{R}\)&#xD;&#xA;&#xA;, if we consider the equation&#xA;&#xD;&#xA;\(r_1v_1+r_2v_2+...+r_mv_m=0\)&#xD;&#xA;&#xA;with the objective of demonstrating that the vectors in&#xA;&#xD;&#xA;\((v_1,v_2,...,v_m)\)&#xD;&#xA;&#xA;are linearly independent, then we must show that&#xA;&#xD;&#xA;\(r_1=r_2=...=r_m=0\)&#xD;&#xA;. If we take the inner product on both sides of the equation , we have that&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;&amp;lt;r_1v_1+r_2v_2+&amp;hellip;+r_mv_m, v_1&amp;gt; = &amp;lt;0,v_1&amp;gt;&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;Using the properties of inner products, we have that&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Fascinating Integral</title>
      <link>https://drummond.nyc/post/a-fascinating-integral/</link>
      <pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/a-fascinating-integral/</guid>
      <description>&lt;p&gt;We will evalute the integral&#xA;&#xD;&#xA;\(\int_0^1 \frac{\ln(x)}{1+x} dx \)&#xD;&#xA;&#xA;using Taylor Series expansion and switching the order of integration and summation.&lt;/p&gt;&#xA;&lt;p&gt;Firstly, we notice that&#xA;$$&#xA;\frac{1}{1+x}=\sum_{n=0}^{\infty} (-1)^n x^n&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;by taylor series expansion. This series coverges for&#xA;&#xD;&#xA;\(x \in (0,1)\)&#xD;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;so we can substitute this into the integral:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\int_0^1 \frac{\ln(x)}{1+x} dx = \int_0^1 \ln(x) \sum_{n=0}^{\infty} (-1)^n x^n dx&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;Further, by changing the order of integration and summation, we have&#xA;$$&#xA;\int_0^1 \ln(x) \sum_{n=0}^{\infty} (-1)^n x^n dx = \sum_{n=0}^{\infty} (-1)^n \int_0^1 x^n \ln(x) dx&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://drummond.nyc/about/</link>
      <pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/about/</guid>
      <description>&lt;p&gt;I am graduate student in mathematics currently studying at Rutgers University. I graduated in May 2022 with my Bachelor&amp;rsquo;s in Mathematics at New York University. My interests include geometric analysis, differential geometry and geometric flows. Currently, I am completing a Master&amp;rsquo;s Thesis on Energy Minimizing Maps and the application of Simon-Lojasiewicz to the uniqueness of tangent maps/flows under Professor Natasa Sesum. These are my two beloved dogs Piper and Molly. Piper is a red heeler mix, and Molly is a blue heeler Australian Cattle Dog.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basel Problem</title>
      <link>https://drummond.nyc/post/basel-problem/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://drummond.nyc/post/basel-problem/</guid>
      <description>&lt;p&gt;The Basel Problem, named after Leonard Euler&amp;rsquo;s hometown of Basel, Switzerland, is the solution to the infinite series&#xA;&#xD;&#xA;\(\sum_{n=1}^{\infty} \frac{\pi^2}{6}\)&#xD;&#xA;&#xA;Euler was the first to publish his solution one year after having solved this problem in 1734. Since Euler&amp;rsquo;s solution, many alternative proofs have been offered, using complex analysis, symmetric polynomials, and so on. These alternative proofs are more rigorous than Euler&amp;rsquo;s liberal use of infinite polyomial tails, but Euler&amp;rsquo;s solution is perhaps the most elegant. This is the outline of the proof.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
